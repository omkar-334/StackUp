{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a06f64d6",
   "metadata": {},
   "source": [
    "# Introduction to NLP in Python\n",
    "## Quest 1: NLP Basics for Text Preprocessing\n",
    "\n",
    "### Tokenization\n",
    "\n",
    "Tokenizers divide strings into lists of substrings. After installing the nltk library, let's import the library along with these two built-in methods, *sent_tokenize* and *word_tokenize*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c6aa87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f673677b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import sent_tokenize\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "35c6b267",
   "metadata": {},
   "source": [
    "1. `sent_tokenize`\n",
    "\n",
    "The first method, `sent_tokenize`, splits the given text into sentences. This is useful especially if you are dealing with bigger chunks of text with longer sentences.\n",
    "\n",
    "We will make use of the following sample paragraph about NLP in the healthcare industry. Run the cell below to check out the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d6c0ebb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sample = \"The wind shook some blossoms from the trees, and the heavy lilac-blooms, with their clustering stars, moved to and fro in the languid air. A grasshopper began to chirrup by the wall, and like a blue thread a long thin dragon-fly floated past on its brown gauze wings. Lord Henry felt as if he could hear Basil Hallward’s heart beating, and wondered what was coming.\"\n",
    "sentence_tokens=sent_tokenize(sample)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4650cb69",
   "metadata": {},
   "source": [
    "If you encounter the \"Resource punkt not found\" error when running the above cell, you can run the following command `nltk.download('punkt')`\n",
    "<br/><br/>\n",
    "\n",
    "2. `word_tokenize`\n",
    "\n",
    "Likewise, the `word_tokenize` method tokenizes each individual word in the paragraph. Run the cell below to compare the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b00bd69",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'wind', 'shook', 'some', 'blossoms', 'from', 'the', 'trees', ',', 'and', 'the', 'heavy', 'lilac-blooms', ',', 'with', 'their', 'clustering', 'stars', ',', 'moved', 'to', 'and', 'fro', 'in', 'the', 'languid', 'air', '.', 'A', 'grasshopper', 'began', 'to', 'chirrup', 'by', 'the', 'wall', ',', 'and', 'like', 'a', 'blue', 'thread', 'a', 'long', 'thin', 'dragon-fly', 'floated', 'past', 'on', 'its', 'brown', 'gauze', 'wings', '.', 'Lord', 'Henry', 'felt', 'as', 'if', 'he', 'could', 'hear', 'Basil', 'Hallward', '’', 's', 'heart', 'beating', ',', 'and', 'wondered', 'what', 'was', 'coming', '.']\n"
     ]
    }
   ],
   "source": [
    "word_tokens=word_tokenize(sample)\n",
    "print(word_tokens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5908050b",
   "metadata": {},
   "source": [
    "Additionally, feel free to experiment with different sentences and pieces of text and passing them through each tokenizer. \n",
    "\n",
    "There are many more types of tokenizers in the nltk library itself, catered to producing various tokens based on the type of data that is needed. You can learn more about tokenizers from the nltk documentation [here](https://www.nltk.org/api/nltk.tokenize.html).\n",
    "\n",
    "Return back to the StackUp platform, where we will continue on with the quest.\n",
    "\n",
    "<br/><br/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7a894c1a",
   "metadata": {},
   "source": [
    "### Removing stop words\n",
    "\n",
    "Stop words are the common words which don't really add much meaning to the text. Some stop words in English includes conjunctions such as for, and, but, or, yet, so, and articles such as a, an, the.\n",
    "\n",
    "NLTK has pre-defined stop words for English. Let's go ahead and import it by running in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "577c7d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b226b1dd",
   "metadata": {},
   "source": [
    "The list stopwords now contains the NLTK predefined stop words. Using the tokenized text from earlier, let's remove the stop words and return the remaining tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55e9e922",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(sample)\n",
    "stopwords_removed = [i for i in tokens if i not in stopwords]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8484e6cc",
   "metadata": {},
   "source": [
    "Now, lets head back to the StackUp platform, where we cover the third preprocessing technique in this quest."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ba3c19d",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "\n",
    "### Stemming and Lemmatization\n",
    "\n",
    "Here, we will experiment using the PorterStemmer and WordNetLemmatizer. Recall from the quest that stemming removes the suffix from the word while lemmatization takes into account the context and what the word means in the sentence.\n",
    "\n",
    "Play along with different words to compare the outputs produced by a stemmer and a lemmatizer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ccbc57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading wordnet: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n",
      "[nltk_data] Error loading omw-1.4: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "stemmer = PorterStemmer()\n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5aa877b4",
   "metadata": {},
   "source": [
    "Let's test both methods on various pluralised words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b16dff8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemming results:  ['the', 'wind', 'shook', 'blossom', 'tree', ',', 'heavi', 'lilac-bloom', ',', 'cluster', 'star', ',', 'move', 'fro', 'languid', 'air', '.', 'a', 'grasshopp', 'began', 'chirrup', 'wall', ',', 'like', 'blue', 'thread', 'long', 'thin', 'dragon-fli', 'float', 'past', 'brown', 'gauz', 'wing', '.', 'lord', 'henri', 'felt', 'could', 'hear', 'basil', 'hallward', '’', 'heart', 'beat', ',', 'wonder', 'come', '.']\n",
      "Lemmatization results;  ['The', 'wind', 'shook', 'blossom', 'tree', ',', 'heavy', 'lilac-blooms', ',', 'clustering', 'star', ',', 'moved', 'fro', 'languid', 'air', '.', 'A', 'grasshopper', 'began', 'chirrup', 'wall', ',', 'like', 'blue', 'thread', 'long', 'thin', 'dragon-fly', 'floated', 'past', 'brown', 'gauze', 'wing', '.', 'Lord', 'Henry', 'felt', 'could', 'hear', 'Basil', 'Hallward', '’', 'heart', 'beating', ',', 'wondered', 'coming', '.']\n"
     ]
    }
   ],
   "source": [
    "plurals = ['apples', 'octopuses', 'categories', 'criteria', 'tomatoes', 'matrices', 'hypotheses', 'radii', 'algae', 'cacti']\n",
    "\n",
    "sample_stem = [stemmer.stem(plural) for plural in stopwords_removed]\n",
    "sample_lemma = [lemma.lemmatize(plural) for plural in stopwords_removed]\n",
    "\n",
    "print(\"Stemming results: \", sample_stem)\n",
    "print(\"Lemmatization results; \", sample_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f66d68e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The wind shook some blossoms from the trees, and the heavy lilac-blooms, with their clustering stars, moved to and fro in the languid air. A grasshopper began to chirrup by the wall, and like a blue thread a long thin dragon-fly floated past on its brown gauze wings. Lord Henry felt as if he could hear Basil Hallward’s heart beating, and wondered what was coming. \n",
      "\n",
      "['The wind shook some blossoms from the trees, and the heavy lilac-blooms, with their clustering stars, moved to and fro in the languid air.', 'A grasshopper began to chirrup by the wall, and like a blue thread a long thin dragon-fly floated past on its brown gauze wings.', 'Lord Henry felt as if he could hear Basil Hallward’s heart beating, and wondered what was coming.'] \n",
      "\n",
      "['The', 'wind', 'shook', 'some', 'blossoms', 'from', 'the', 'trees', ',', 'and', 'the', 'heavy', 'lilac-blooms', ',', 'with', 'their', 'clustering', 'stars', ',', 'moved', 'to', 'and', 'fro', 'in', 'the', 'languid', 'air', '.', 'A', 'grasshopper', 'began', 'to', 'chirrup', 'by', 'the', 'wall', ',', 'and', 'like', 'a', 'blue', 'thread', 'a', 'long', 'thin', 'dragon-fly', 'floated', 'past', 'on', 'its', 'brown', 'gauze', 'wings', '.', 'Lord', 'Henry', 'felt', 'as', 'if', 'he', 'could', 'hear', 'Basil', 'Hallward', '’', 's', 'heart', 'beating', ',', 'and', 'wondered', 'what', 'was', 'coming', '.'] \n",
      "\n",
      "['The', 'wind', 'shook', 'blossoms', 'trees', ',', 'heavy', 'lilac-blooms', ',', 'clustering', 'stars', ',', 'moved', 'fro', 'languid', 'air', '.', 'A', 'grasshopper', 'began', 'chirrup', 'wall', ',', 'like', 'blue', 'thread', 'long', 'thin', 'dragon-fly', 'floated', 'past', 'brown', 'gauze', 'wings', '.', 'Lord', 'Henry', 'felt', 'could', 'hear', 'Basil', 'Hallward', '’', 'heart', 'beating', ',', 'wondered', 'coming', '.'] \n",
      "\n",
      "Stemming results:  ['the', 'wind', 'shook', 'blossom', 'tree', ',', 'heavi', 'lilac-bloom', ',', 'cluster', 'star', ',', 'move', 'fro', 'languid', 'air', '.', 'a', 'grasshopp', 'began', 'chirrup', 'wall', ',', 'like', 'blue', 'thread', 'long', 'thin', 'dragon-fli', 'float', 'past', 'brown', 'gauz', 'wing', '.', 'lord', 'henri', 'felt', 'could', 'hear', 'basil', 'hallward', '’', 'heart', 'beat', ',', 'wonder', 'come', '.'] \n",
      "\n",
      "Lemmatization results:  ['The', 'wind', 'shook', 'blossom', 'tree', ',', 'heavy', 'lilac-blooms', ',', 'clustering', 'star', ',', 'moved', 'fro', 'languid', 'air', '.', 'A', 'grasshopper', 'began', 'chirrup', 'wall', ',', 'like', 'blue', 'thread', 'long', 'thin', 'dragon-fly', 'floated', 'past', 'brown', 'gauze', 'wing', '.', 'Lord', 'Henry', 'felt', 'could', 'hear', 'Basil', 'Hallward', '’', 'heart', 'beating', ',', 'wondered', 'coming', '.']\n"
     ]
    }
   ],
   "source": [
    "print(sample,\"\\n\")\n",
    "print(sentence_tokens,\"\\n\")\n",
    "print(word_tokens,\"\\n\")\n",
    "print(stopwords_removed,\"\\n\")\n",
    "print(\"Stemming results: \", sample_stem,\"\\n\")\n",
    "print(\"Lemmatization results: \", sample_lemma)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "403f0a6a",
   "metadata": {},
   "source": [
    "Compare the results produced above! The lemmatizer is more accurate when it comes to getting the root word of more complex plurals, however it is important to note that in the case of a large dataset, stemming comes in handy where performance is an issue. \n",
    "\n",
    "And that sums up the 3 techniques for text preprocessing in NLP! **Return back to the StackUp platform,** where we wrap up the quest and prepare the deliverables for submission. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
